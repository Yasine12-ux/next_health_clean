{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Token Dictionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'``': 1,\n",
       " 'patient': 2,\n",
       " 'souffr': 3,\n",
       " 'maux': 4,\n",
       " 'têt': 5,\n",
       " 'fréquent': 6,\n",
       " 'fatigu': 7,\n",
       " '.': 8,\n",
       " \"''\": 9,\n",
       " 'a': 10,\n",
       " 'glycem': 11,\n",
       " 'élev': 12,\n",
       " 'douleur': 13,\n",
       " 'abdominal': 14,\n",
       " 'musculair': 15,\n",
       " 'apres': 16,\n",
       " \"l'exercic\": 17,\n",
       " 'plaint': 18,\n",
       " 'vertig': 19,\n",
       " 'palpit': 20,\n",
       " 'hypertens': 21,\n",
       " 'mal': 22,\n",
       " 'contrôl': 23,\n",
       " 'hypercholestérolem': 24,\n",
       " 'articulair': 25,\n",
       " 'raideur': 26,\n",
       " 'présent': 27,\n",
       " 'symptôm': 28,\n",
       " 'diabet': 29,\n",
       " 'pelvien': 30,\n",
       " 'cramp': 31,\n",
       " 'thorac': 32,\n",
       " 'dyspn': 33,\n",
       " \"l'effort\": 34,\n",
       " 'dépress': 35,\n",
       " \"d'anxiet\": 36,\n",
       " 'indigest': 37,\n",
       " 'bouff': 38,\n",
       " 'chaleur': 39,\n",
       " 'sueur': 40,\n",
       " 'nocturn': 41,\n",
       " 'engourd': 42,\n",
       " 'extrem': 43,\n",
       " 'migrain': 44,\n",
       " 'séver': 45,\n",
       " 'toux': 46,\n",
       " 'persist': 47,\n",
       " 'lombair': 48,\n",
       " 'chroniqu': 49,\n",
       " 'neuropath': 50,\n",
       " 'pied': 51,\n",
       " 'sinusit': 52,\n",
       " 'insuffis': 53,\n",
       " 'cardiaqu': 54,\n",
       " 'congest': 55,\n",
       " 'cervical': 56,\n",
       " 'allerg': 57,\n",
       " 'saisonni': 58,\n",
       " 'menstruel': 59,\n",
       " 'troubl': 60,\n",
       " 'sommeil': 61,\n",
       " \"l'anxiet\": 62,\n",
       " 'hyperglycem': 63,\n",
       " 'dyslipidem': 64,\n",
       " 'saign': 65,\n",
       " 'abond': 66,\n",
       " 'ballon': 67,\n",
       " 'ménopaus': 68,\n",
       " 'angin': 69,\n",
       " 'poitrin': 70,\n",
       " 'post-partum': 71,\n",
       " 'tendinit': 72,\n",
       " 'poignet': 73,\n",
       " 'droit': 74,\n",
       " 'léger': 75,\n",
       " 'fievr': 76,\n",
       " \"d'hypertens\": 77,\n",
       " 'pression': 78,\n",
       " 'artériel': 79,\n",
       " 'sensat': 80,\n",
       " 'soif': 81,\n",
       " 'intens': 82,\n",
       " 'naus': 83,\n",
       " 'non': 84,\n",
       " 'faibless': 85,\n",
       " 'enflé': 86,\n",
       " \"l'épaul\": 87,\n",
       " 'suit': 88,\n",
       " 'blessur': 89,\n",
       " 'sportiv': 90,\n",
       " 'difficult': 91,\n",
       " 'respiratoir': 92,\n",
       " 'récurrent': 93,\n",
       " 'genou': 94,\n",
       " 'chut': 95,\n",
       " 'hanch': 96,\n",
       " 'moder': 97,\n",
       " \"d'apn\": 98,\n",
       " 'aigu': 99,\n",
       " 'péripher': 100,\n",
       " 'lombalg': 101,\n",
       " 'céphal': 102,\n",
       " 'tension': 103,\n",
       " 'du': 104,\n",
       " 'cystit': 105,\n",
       " 'stabl': 106,\n",
       " 'polyneuropath': 107,\n",
       " 'dorsal': 108,\n",
       " 'arthros': 109,\n",
       " 'infect': 110,\n",
       " 'urinair': 111,\n",
       " 'jamb': 112,\n",
       " 'accouch': 113,\n",
       " 'récent': 114,\n",
       " 'exercic': 115,\n",
       " 'niveau': 116,\n",
       " 'sucr': 117,\n",
       " 'sang': 118}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DICT_PATH = \"tokenizer_dict.pkl\"\n",
    "MODEL_PATH = 'knn_model.joblib'\n",
    "NUM_PREPROCSS_PATH = \"numeric_transformer.joblib\"\n",
    "CAT_PREPROCSS_PATH = \"categorical_transformer.joblib\"\n",
    "\n",
    "BASE_PATH = \"modeldata/\"\n",
    "\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "dictionary={}\n",
    "with open(BASE_PATH+DICT_PATH, 'rb') as f:\n",
    "    dictionary=pickle.load(f)\n",
    "knn = joblib.load(BASE_PATH+\"knn_model.joblib\")\n",
    "\n",
    "numeric_transformer=joblib.load(BASE_PATH+NUM_PREPROCSS_PATH)\n",
    "categorical_transformer=joblib.load(BASE_PATH+CAT_PREPROCSS_PATH)\n",
    "\n",
    "dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Aziz\n",
      "[nltk_data]     Hlila\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Aziz\n",
      "[nltk_data]     Hlila\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "# load data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Download NLTK resources (if not already downloaded)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize NLTK's SnowballStemmer and stopwords for French\n",
    "stemmer = SnowballStemmer('french')\n",
    "stop_words = set(stopwords.words('french'))\n",
    "\n",
    "def tokenizeText(text, dictionary):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize text using NLTK tokenizer\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Apply stemming using SnowballStemmer\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Numerize tokens\n",
    "    numerical_tokens = []\n",
    "    for token in stemmed_tokens:\n",
    "        if token not in dictionary:\n",
    "            # dictionary[token] = torch.tensor(len(dictionary) + 1,dtype=torch.int32)\n",
    "            dictionary[token] = len(dictionary) + 1\n",
    "        numerical_tokens.append(dictionary[token])\n",
    "    \n",
    "    # Convert numerical tokens and dictionary values to tensors\n",
    "    # numerical_tokens_tensor = torch.tensor(numerical_tokens)\n",
    "    numerical_tokens_np = np.array(numerical_tokens)\n",
    "    # return numerical_tokens_tensor\n",
    "    return numerical_tokens_np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sequence_list, maxlen=None):\n",
    "    if not maxlen:\n",
    "        maxlen = max(len(seq) for seq in sequence_list)\n",
    "    padded_sequences = np.zeros((len(sequence_list), maxlen), dtype=int)\n",
    "    for i, seq in enumerate(sequence_list):\n",
    "        if len(seq) > 0:  # Check if the sequence is not empty\n",
    "            padded_sequences[i, :len(seq)] = seq\n",
    "    return padded_sequences\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X = pd.read_csv(\"validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
       "Name: Description, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptionsTokenized = X['Description'].apply(lambda x: tokenizeText(x, dictionary))\n",
    "descriptionsTokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptionsTokenizedPadded = pad_sequences(descriptionsTokenized,300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np \n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "numeric_features = ['tailleCm', 'poidsKg', 'IMC', 'nbGrossesse', 'nbEnfantsVivants',\n",
    "                    'nbMacrosomies', 'nbAvortements', 'nbMortNes', 'ageMenopause',\n",
    "                    'alcoolSemaine', 'nbCigaretteParJour', 'Age']\n",
    "categorical_features = ['groupeSanguin', 'HTA', 'diabete', 'dyslipidemie', 'tabacStatus',\n",
    "                        'drogue']\n",
    "\n",
    "numeric_transformed = numeric_transformer.transform(X[numeric_features].to_numpy())\n",
    "\n",
    "categorical_transformed  = categorical_transformer.transform(X[categorical_features].to_numpy())\n",
    "\n",
    "preprocessed_data = np.hstack((numeric_transformed, categorical_transformed.toarray()))\n",
    "X_combined = np.hstack((preprocessed_data, descriptionsTokenizedPadded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , 12.32882801, 16.39980687, 16.39980687, 16.39980687,\n",
       "        18.38849449, 20.41973872, 20.9001628 , 20.9001628 , 22.15747426]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "distances, indices = knn.kneighbors(X_combined, n_neighbors=10)\n",
    "# Convert indices to actual predictions\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
