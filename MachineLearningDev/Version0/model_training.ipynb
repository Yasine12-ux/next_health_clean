{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Aziz\n",
      "[nltk_data]     Hlila\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Aziz\n",
      "[nltk_data]     Hlila\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "# load data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Download NLTK resources (if not already downloaded)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize NLTK's SnowballStemmer and stopwords for French\n",
    "stemmer = SnowballStemmer('french')\n",
    "stop_words = set(stopwords.words('french'))\n",
    "\n",
    "dictionary = {}\n",
    "\n",
    "\n",
    "def tokenizeText(text, dictionary):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize text using NLTK tokenizer\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Apply stemming using SnowballStemmer\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Numerize tokens\n",
    "    numerical_tokens = []\n",
    "    for token in stemmed_tokens:\n",
    "        if token not in dictionary:\n",
    "            # dictionary[token] = torch.tensor(len(dictionary) + 1,dtype=torch.int32)\n",
    "            dictionary[token] = len(dictionary) + 1\n",
    "        numerical_tokens.append(dictionary[token])\n",
    "    \n",
    "    # Convert numerical tokens and dictionary values to tensors\n",
    "    # numerical_tokens_tensor = torch.tensor(numerical_tokens)\n",
    "    numerical_tokens_np = np.array(numerical_tokens)\n",
    "    # return numerical_tokens_tensor\n",
    "    return numerical_tokens_np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(424, 23)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.read_csv(\"data_cleanOutput.csv\")\n",
    "\n",
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
       "1      [1, 2, 10, 11, 12, 13, 14, 8, 9]\n",
       "2      [1, 2, 10, 13, 15, 16, 17, 8, 9]\n",
       "3              [1, 2, 18, 19, 20, 8, 9]\n",
       "4      [1, 2, 10, 21, 22, 23, 24, 8, 9]\n",
       "                     ...               \n",
       "419       [1, 2, 27, 13, 108, 49, 8, 9]\n",
       "420             [1, 2, 18, 7, 19, 8, 9]\n",
       "421       [1, 2, 27, 109, 94, 74, 8, 9]\n",
       "422             [1, 2, 18, 44, 6, 8, 9]\n",
       "423           [1, 2, 27, 101, 49, 8, 9]\n",
       "Name: Description, Length: 424, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary={}\n",
    "descriptionsTokenized = df_full['Description'].apply(lambda x: tokenizeText(x, dictionary))\n",
    "descriptionsTokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(424, 300)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>108</td>\n",
       "      <td>49</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>109</td>\n",
       "      <td>94</td>\n",
       "      <td>74</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>101</td>\n",
       "      <td>49</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>424 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1   2    3    4   5   6  7  8  9  ...  290  291  292  293  294  295  \\\n",
       "0    1  2   3    4    5   6   7  8  9  0  ...    0    0    0    0    0    0   \n",
       "1    1  2  10   11   12  13  14  8  9  0  ...    0    0    0    0    0    0   \n",
       "2    1  2  10   13   15  16  17  8  9  0  ...    0    0    0    0    0    0   \n",
       "3    1  2  18   19   20   8   9  0  0  0  ...    0    0    0    0    0    0   \n",
       "4    1  2  10   21   22  23  24  8  9  0  ...    0    0    0    0    0    0   \n",
       "..  .. ..  ..  ...  ...  ..  .. .. .. ..  ...  ...  ...  ...  ...  ...  ...   \n",
       "419  1  2  27   13  108  49   8  9  0  0  ...    0    0    0    0    0    0   \n",
       "420  1  2  18    7   19   8   9  0  0  0  ...    0    0    0    0    0    0   \n",
       "421  1  2  27  109   94  74   8  9  0  0  ...    0    0    0    0    0    0   \n",
       "422  1  2  18   44    6   8   9  0  0  0  ...    0    0    0    0    0    0   \n",
       "423  1  2  27  101   49   8   9  0  0  0  ...    0    0    0    0    0    0   \n",
       "\n",
       "     296  297  298  299  \n",
       "0      0    0    0    0  \n",
       "1      0    0    0    0  \n",
       "2      0    0    0    0  \n",
       "3      0    0    0    0  \n",
       "4      0    0    0    0  \n",
       "..   ...  ...  ...  ...  \n",
       "419    0    0    0    0  \n",
       "420    0    0    0    0  \n",
       "421    0    0    0    0  \n",
       "422    0    0    0    0  \n",
       "423    0    0    0    0  \n",
       "\n",
       "[424 rows x 300 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pad_sequences(sequence_list, maxlen=None):\n",
    "    if not maxlen:\n",
    "        maxlen = max(len(seq) for seq in sequence_list)\n",
    "    padded_sequences = np.zeros((len(sequence_list), maxlen), dtype=int)\n",
    "    for i, seq in enumerate(sequence_list):\n",
    "        if len(seq) > 0:  # Check if the sequence is not empty\n",
    "            padded_sequences[i, :len(seq)] = seq\n",
    "    return padded_sequences\n",
    "\n",
    "descriptionsTokenizedPadded = pad_sequences(descriptionsTokenized,300)\n",
    "print(descriptionsTokenizedPadded.shape)\n",
    "df_tokens = pd.DataFrame(data=descriptionsTokenizedPadded,index=df_full.index).rename(columns=str)\n",
    "df_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(424, 22)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_full.drop(columns=['Ordonnance'])\n",
    "y = df_full['Ordonnance']\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tailleCm\n",
       "160    51\n",
       "165    47\n",
       "170    43\n",
       "175    37\n",
       "162    35\n",
       "180    33\n",
       "168    29\n",
       "178    24\n",
       "172    21\n",
       "158    17\n",
       "176    16\n",
       "174    13\n",
       "182    12\n",
       "155     9\n",
       "164     8\n",
       "173     4\n",
       "167     4\n",
       "177     4\n",
       "185     4\n",
       "163     3\n",
       "183     3\n",
       "169     2\n",
       "159     2\n",
       "157     1\n",
       "161     1\n",
       "166     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[\"tailleCm\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "# List of numeric and categorical features\n",
    "numeric_features = ['tailleCm', 'poidsKg', 'IMC', 'nbGrossesse', 'nbEnfantsVivants',\n",
    "                    'nbMacrosomies', 'nbAvortements', 'nbMortNes', 'ageMenopause',\n",
    "                    'alcoolSemaine', 'nbCigaretteParJour', 'Age']\n",
    "categorical_features = ['groupeSanguin', 'HTA', 'diabete', 'dyslipidemie', 'tabacStatus',\n",
    "                        'drogue']\n",
    "\n",
    "\n",
    "# Preprocessing pipelines for numeric and categorical data\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())])\n",
    "numeric_transformed = numeric_transformer.fit_transform(X[numeric_features].to_numpy())\n",
    "\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "categorical_transformed  = categorical_transformer.fit_transform(X[categorical_features].to_numpy())\n",
    "\n",
    "preprocessed_data = np.hstack((numeric_transformed, categorical_transformed.toarray()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(424, 330)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_combined = np.hstack((preprocessed_data, descriptionsTokenizedPadded))\n",
    "print(X_combined.shape)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6352941176470588\n",
      "(85, 330)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8941176470588236\n",
      "(85, 330)\n"
     ]
    }
   ],
   "source": [
    "## train all \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "knn_product = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "knn_product.fit(X_combined, y)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = knn_product.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, indices = knn.kneighbors(X_test, n_neighbors=10)\n",
    "# Convert indices to actual predictions\n",
    "top_k_predictions = np.array(y_train)[indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-3 Accuracy: 92.9%\n",
      "Mean Reciprocal Rank: 93.1%\n",
      "Coverage at 3: 77.2%\n"
     ]
    }
   ],
   "source": [
    "def top_n_accuracy(y_true, y_pred, n=3):\n",
    "    top_n_correct = 0\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        if true in pred[:n]:\n",
    "            top_n_correct += 1\n",
    "    return top_n_correct / len(y_true)\n",
    "\n",
    "def mean_reciprocal_rank(y_true, y_pred):\n",
    "    rr_sum = 0\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        if true in pred:\n",
    "            rr_sum += 1 / (pred.tolist().index(true) + 1)\n",
    "    return rr_sum / len(y_true)\n",
    "\n",
    "def precision_at_k(y_true, y_pred, k=3):\n",
    "    precision_sum = 0\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        if true in pred[:k]:\n",
    "            precision_sum += 1\n",
    "    return precision_sum / (k * len(y_true))\n",
    "\n",
    "def coverage(y_pred, all_items, k=3):\n",
    "    recommended_items = set()\n",
    "    for pred in y_pred:\n",
    "        recommended_items.update(pred[:k])\n",
    "    return len(recommended_items) / len(all_items)\n",
    "\n",
    "# Example: Evaluating the top 3 recommendations\n",
    "top_3_acc = top_n_accuracy(y_test, top_k_predictions, n=5)\n",
    "mrr = mean_reciprocal_rank(y_test, top_k_predictions)\n",
    "precision_k = precision_at_k(y_test, top_k_predictions, k=5)\n",
    "all_possible_items = set(y_train)  # Use the unique items from the training set as all possible items\n",
    "coverage_score = coverage(top_k_predictions, all_possible_items, k=5)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Top-3 Accuracy: {top_3_acc*100:.1f}%\")\n",
    "print(f\"Mean Reciprocal Rank: {mrr*100:.1f}%\")\n",
    "print(f\"Coverage at 3: {coverage_score*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pickle\n",
    "\n",
    "joblib.dump(knn, 'modeldata/knn_model.joblib')\n",
    "with open('modeldata/tokenizer_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(dictionary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modeldata/categorical_transformer.joblib']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_transformer_file = 'modeldata/numeric_transformer.joblib'\n",
    "categorical_transformer_file = 'modeldata/categorical_transformer.joblib'\n",
    "\n",
    "joblib.dump(numeric_transformer,numeric_transformer_file)\n",
    "joblib.dump(categorical_transformer,categorical_transformer_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
